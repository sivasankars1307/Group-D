# ğŸ™ï¸ Hand Gestureâ€“Based Volume Control

A real-time **gesture-controlled volume system** built with **Streamlit**, **MediaPipe**, **OpenCV**, and **PyCAW**. The application allows users to **mute/unmute** and **adjust microphone volume** using **thumbâ€“index finger gestures**, with scale-invariant normalization for stability.

This project was developed as part of the **Infosys SpringBoard** program.

---

## ğŸš€ Features

* âœ‹ **Real-time hand tracking** using MediaPipe (single-hand, low-latency)
* ğŸ”‡ **Pinch-to-mute** gesture (thumb + index close)
* ğŸ”Š **Continuous microphone volume control** using finger distance
* ğŸ“ **Scale-invariant ratio calculation** (robust to hand distance from camera)
* ğŸ›ï¸ **Manual volume controls** (+20% / âˆ’20%) in sidebar
* ğŸ¥ **Live camera feed** with visual landmarks
* ğŸ§Š  built with Streamlit + custom CSS

---

## ğŸ§  How It Works (Core Logic)

1. Capture frames from webcam using OpenCV
2. Detect hand landmarks using MediaPipe Hands
3. Extract key landmarks:

   * Thumb tip (ID 4)
   * Index tip (ID 8)
   * Wrist (ID 0)
   * Middle finger MCP (ID 9)
4. Compute:

```
Pinch Ratio = Distance(Thumb, Index) / Distance(Wrist, Middle MCP)
```

5. Apply logic:

   * **Ratio â‰¤ 0.15** â†’ Microphone muted
   * **Ratio > 0.15** â†’ Map ratio to volume (0â€“100%)
6. Set microphone volume using **Windows Core Audio API (PyCAW)**

---

## ğŸ–¥ï¸ System Requirements

| Requirement | Details                            |
| ----------- | ---------------------------------- |
| OS          | **Windows 10 / 11 only**           |
| Python      | 3.9 â€“ 3.11 (3.10 recommended)      |
| Hardware    | Webcam + Microphone                |
| Permissions | Camera & Microphone access enabled |

> âš ï¸ This project will **not work on macOS or Linux** due to Windows-specific audio APIs.

---

## ğŸ“¦ Dependencies

Install the required libraries:

```bash
pip install streamlit opencv-python mediapipe numpy pycaw comtypes
```

---

## â–¶ï¸ How to Run

1. Clone the repository

```bash
git clone <repo-url>
cd <repo-folder>
```

2. (Recommended) Create a virtual environment

```bash
python -m venv venv
venv\Scripts\activate
```

3. Run the Streamlit app

```bash
streamlit run main.py
```

4. Open the browser at:

```
http://localhost:8501
```

---

## ğŸ® Usage Instructions

1. Click **START CAMERA**
2. Show **one hand only** to the webcam
3. Gestures:

   * ğŸ¤ **Thumb + Index close** â†’ Mute microphone
   * â†”ï¸ **Increase distance** â†’ Increase mic volume
   * â†•ï¸ **Decrease distance** â†’ Decrease mic volume
4. Use sidebar buttons for manual volume control if needed

---

## âš™ï¸ Configuration Parameters

You can fine-tune gesture sensitivity in the code:

```python
PINCH_RATIO_THRESHOLD = 0.15  # Mute threshold
MIN_RATIO = 0.15             # 0% volume
MAX_RATIO = 1.5              # 100% volume
SMOOTHING = 3                # Volume smoothing step
```

---

## ğŸ§ª Known Limitations

* Single-hand tracking only
* Requires good lighting for accurate detection
* Background clutter may affect hand tracking
* Windows-only microphone control

---

## ğŸ§  System Architecture

### High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Webcam     â”‚
â”‚ (Video Feed) â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ OpenCV
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Frame Preprocessing   â”‚
â”‚  - Flip
â”‚  - RGB Conversion      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MediaPipe Hands       â”‚
â”‚  - Landmark Detection  â”‚
â”‚  - 21 key points       â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Gesture Analysis Logic â”‚
â”‚ - Thumbâ€“Index Distanceâ”‚
â”‚ - Wristâ€“MCP Scale     â”‚
â”‚ - Ratio Normalization â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Decision Engine        â”‚
â”‚ - Pinch â†’ Mute         â”‚
â”‚ - Spread â†’ Volume Map  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ PyCAW (COM API)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Windows Audio Engine   â”‚
â”‚ (Microphone Control)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â–²
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Streamlit UI Layer     â”‚
â”‚ - Metrics              â”‚
â”‚ - Status               â”‚
â”‚ - Live Video           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Architectural Design Choices

* **Scale-invariant ratio** prevents false volume changes due to hand depth
* **Single-hand tracking** reduces latency and CPU usage
* **Cached MediaPipe model** avoids repeated initialization
* **COM interface instantiated once** for stability
* **UI + processing loop tightly synchronized** via Streamlit session state

---

## ğŸ” Processing Flowchart

### Runtime Execution Flow

```
START
  â”‚
  â–¼
Initialize Streamlit UI
  â”‚
  â–¼
Load MediaPipe Hand Model (cached)
  â”‚
  â–¼
User clicks START CAMERA
  â”‚
  â–¼
Open Webcam Stream
  â”‚
  â–¼
Read Frame
  â”‚
  â–¼
Convert BGR â†’ RGB
  â”‚
  â–¼
Detect Hand Landmarks
  â”‚
  â–¼
Hand Detected?
  â”œâ”€â”€ NO â†’ Show camera feed only
  â”‚
  â””â”€â”€ YES
        â”‚
        â–¼
   Extract Key Landmarks
        â”‚
        â–¼
   Compute Pinch Ratio
        â”‚
        â–¼
   Ratio â‰¤ Threshold?
        â”œâ”€â”€ YES â†’ MUTE MICROPHONE
        â”‚
        â””â”€â”€ NO  â†’ Map Ratio â†’ Volume %
                  â”‚
                  â–¼
             Set Mic Volume
        
  â”‚
  â–¼
Update UI Metrics & Status
  â”‚
  â–¼
Display Annotated Frame
  â”‚
  â–¼
STOP CAMERA?
  â”œâ”€â”€ NO â†’ Loop
  â””â”€â”€ YES â†’ Release Camera & Exit
```

---

## ğŸ› ï¸ Tech Stack

* **Python**
* **Streamlit** â€“ UI & app framework
* **MediaPipe** â€“ Hand landmark detection
* **OpenCV** â€“ Video processing
* **PyCAW** â€“ Windows microphone control
* **NumPy** â€“ Numeric mapping & interpolation

---

## ğŸ‘¥ Team

* Anusuya
* Prashanti
* Shreyas
* Siva Sankar

**Mentor:** Dr. D. Bhanu Prakash

---

## ğŸ“œ License

This project is intended for **educational and academic use**.

---

## âœ… Evaluation Readiness

âœ” Real-time system
âœ” Hardware interaction
âœ” OS-level API usage
âœ” Gesture normalization
âœ” Production-style UI

This is **not a toy project**. It demonstrates applied computer vision + system programming.
