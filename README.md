# ğŸ™ï¸ Hand Gestureâ€“Based Volume Control

A real-time **gesture-controlled volume system** built with **Streamlit**, **MediaPipe**, **OpenCV**, and **PyCAW**. The application allows users to **mute/unmute** and **adjust microphone volume** using **thumbâ€“index finger gestures**, with scale-invariant normalization for stability.

This project was developed as part of the **Infosys SpringBoard** program.

---

## ğŸš€ Features

* âœ‹ **Real-time hand tracking** using MediaPipe (single-hand, low-latency)
* ğŸ”‡ **Pinch-to-mute** gesture (thumb + index close)
* ğŸ”Š **Continuous microphone volume control** using finger distance
* ğŸ“ **Scale-invariant ratio calculation** (robust to hand distance from camera)
* ğŸ›ï¸ **Manual volume controls** (+20% / âˆ’20%) in sidebar
* ğŸ¥ **Live camera feed** with visual landmarks
* ğŸ§Š **Apple-inspired UI** built with Streamlit + custom CSS

---

## ğŸ§  How It Works (Core Logic)

1. Capture frames from webcam using OpenCV
2. Detect hand landmarks using MediaPipe Hands
3. Extract key landmarks:

   * Thumb tip (ID 4)
   * Index tip (ID 8)
   * Wrist (ID 0)
   * Middle finger MCP (ID 9)
4. Compute:

```
Pinch Ratio = Distance(Thumb, Index) / Distance(Wrist, Middle MCP)
```

5. Apply logic:

   * **Ratio â‰¤ 0.15** â†’ Microphone muted
   * **Ratio > 0.15** â†’ Map ratio to volume (0â€“100%)
6. Set microphone volume using **Windows Core Audio API (PyCAW)**

---

## ğŸ–¥ï¸ System Requirements

| Requirement | Details                            |
| ----------- | ---------------------------------- |
| OS          | **Windows 10 / 11 only**           |
| Python      | 3.9 â€“ 3.11 (3.10 recommended)      |
| Hardware    | Webcam + Microphone                |
| Permissions | Camera & Microphone access enabled |

> âš ï¸ This project will **not work on macOS or Linux** due to Windows-specific audio APIs.

---

## ğŸ“¦ Dependencies

Install the required libraries:

```bash
pip install streamlit opencv-python mediapipe numpy pycaw comtypes
```

---

## â–¶ï¸ How to Run

1. Clone the repository

```bash
git clone <repo-url>
cd <repo-folder>
```

2. (Recommended) Create a virtual environment

```bash
python -m venv venv
venv\Scripts\activate
```

3. Run the Streamlit app

```bash
streamlit run app.py
```

4. Open the browser at:

```
http://localhost:8501
```

---

## ğŸ® Usage Instructions

1. Click **START CAMERA**
2. Show **one hand only** to the webcam
3. Gestures:

   * ğŸ¤ **Thumb + Index close** â†’ Mute microphone
   * â†”ï¸ **Increase distance** â†’ Increase mic volume
   * â†•ï¸ **Decrease distance** â†’ Decrease mic volume
4. Use sidebar buttons for manual volume control if needed

---

## âš™ï¸ Configuration Parameters

You can fine-tune gesture sensitivity in the code:

```python
PINCH_RATIO_THRESHOLD = 0.15  # Mute threshold
MIN_RATIO = 0.15             # 0% volume
MAX_RATIO = 1.5              # 100% volume
SMOOTHING = 3                # Volume smoothing step
```

---

## ğŸ§ª Known Limitations

* Single-hand tracking only
* Requires good lighting for accurate detection
* Background clutter may affect hand tracking
* Windows-only microphone control

---

## ğŸ› ï¸ Tech Stack

* **Python**
* **Streamlit** â€“ UI & app framework
* **MediaPipe** â€“ Hand landmark detection
* **OpenCV** â€“ Video processing
* **PyCAW** â€“ Windows microphone control
* **NumPy** â€“ Numeric mapping & interpolation

---

## ğŸ‘¥ Team

**Team D**

* Anusuya
* Prashanti
* Shreyas
* Siva Sankar

**Mentor:** Dr. D. Bhanu Prakash

---

## ğŸ“œ License

This project is intended for **educational and academic use**.

---

## âœ… Evaluation Readiness

âœ” Real-time system
âœ” Hardware interaction
âœ” OS-level API usage
âœ” Gesture normalization
âœ” Production-style UI

This is **not a toy project**. It demonstrates applied computer vision + system programming.
